{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='text-align:center;'>NLP Web Scraping & XML Parsing Project</h2>\n",
    "\n",
    "In this project, we parse a **medical article in XML format**, extract structured metadata, clean the article body, and preprocess the text for **Natural Language Processing (NLP)** tasks.\n",
    "\n",
    "**Tech Stack:** Python, XML Parsing (ElementTree), BeautifulSoup, NLTK, Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import xml.etree.ElementTree as ET   # XML parsing\n",
    "from bs4 import BeautifulSoup        # HTML/XML text extraction\n",
    "import re, nltk, string, unicodedata # text cleaning\n",
    "import pandas as pd                  # structured outputs\n",
    "\n",
    "# Download NLTK resources (only first time)\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the XML file\n",
    "We will parse the XML file using `ElementTree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'article'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load XML file\n",
    "xml_file = '../data/769952.xml'\n",
    "tree = ET.parse(xml_file)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Display root tag\n",
    "root.tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Extract Metadata\n",
    "We extract article metadata such as **title, author, publication date, and keywords**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_id': '0901c79180555528',\n",
       " 'journal_title': 'Orphan Drug Approvals',\n",
       " 'article_title': 'FDA Grants Orphan Drug Status to Gevokizumab',\n",
       " 'author': 'Troy Brown',\n",
       " 'publication_date': '29-08-2012',\n",
       " 'keywords': 'choroiditis,cyclitis,intermediate uveitis,orphan drugs,pars planitis,posterior uveitis'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract article ID\n",
    "article_id = root.find('.//article-id').text\n",
    "\n",
    "# Extract journal title\n",
    "journal_title = root.find('.//journal-title').text\n",
    "\n",
    "# Extract article title\n",
    "article_title = root.find('.//article-title').text\n",
    "\n",
    "# Extract author name\n",
    "author = root.find('.//contrib/name/surname').text\n",
    "\n",
    "# Extract publication date\n",
    "pub_day = root.find('.//pub-date/day').text\n",
    "pub_month = root.find('.//pub-date/month').text\n",
    "pub_year = root.find('.//pub-date/year').text\n",
    "pub_date = f\"{pub_day}-{pub_month}-{pub_year}\"\n",
    "\n",
    "# Extract keywords\n",
    "keywords = root.find('.//kwd').text\n",
    "\n",
    "# Store metadata in dictionary\n",
    "metadata = {\n",
    "    'article_id': article_id,\n",
    "    'journal_title': journal_title,\n",
    "    'article_title': article_title,\n",
    "    'author': author,\n",
    "    'publication_date': pub_date,\n",
    "    'keywords': keywords\n",
    "}\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Extract Body Text\n",
    "We collect `<p>` tags inside `<body>` and clean them using BeautifulSoup and regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MUBASSHIR\\anaconda3\\Lib\\html\\parser.py:171: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'WebMD, LLC index Troy Brown is a freelance writer for Medscape. Troy Brown has disclosed no relevant financial relationships.  August 29, 2012 — The US Food and Drug Administration (FDA) has granted orphan drug status to gevokizumab (Xoma 052, Xoma Corp), a monoclonal antibody that binds strongly to interleukin 1β (IL-1β), for the treatment of noninfectious intermediate uveitis, posterior uveitis, or panuveitis, or chronic noninfectious anterior uveitis. The Orphan Drug Act of 1983 was passed to'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert XML to string for BeautifulSoup parsing\n",
    "xml_string = ET.tostring(root, encoding='utf8').decode('utf8')\n",
    "soup = BeautifulSoup(xml_string, \"html.parser\")\n",
    "\n",
    "# Extract all <p> tags from body\n",
    "paragraphs = [p.get_text() for p in soup.find_all('p')]\n",
    "raw_text = ' '.join(paragraphs)\n",
    "\n",
    "# Save raw cleaned text\n",
    "with open('../results/cleaned_text.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(raw_text)\n",
    "\n",
    "raw_text[:500]  # Display sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Text Preprocessing (NLP)\n",
    "We will tokenize, clean, remove stopwords, and lemmatize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['webmd',\n",
       " 'llc',\n",
       " 'index',\n",
       " 'troy',\n",
       " 'brown',\n",
       " 'freelance',\n",
       " 'writer',\n",
       " 'medscape',\n",
       " 'troy',\n",
       " 'brown',\n",
       " 'disclosed',\n",
       " 'relevant',\n",
       " 'financial',\n",
       " 'relationship',\n",
       " 'august',\n",
       " '29',\n",
       " '2012',\n",
       " 'u',\n",
       " 'food',\n",
       " 'drug',\n",
       " 'administration',\n",
       " 'fda',\n",
       " 'granted',\n",
       " 'orphan',\n",
       " 'drug',\n",
       " 'status',\n",
       " 'gevokizumab',\n",
       " 'xoma',\n",
       " '052',\n",
       " 'xoma',\n",
       " 'corp',\n",
       " 'monoclonal',\n",
       " 'antibody',\n",
       " 'bind',\n",
       " 'strongly',\n",
       " 'interleukin',\n",
       " '1',\n",
       " 'il1',\n",
       " 'treatment',\n",
       " 'noninfectious',\n",
       " 'intermediate',\n",
       " 'uveitis',\n",
       " 'posterior',\n",
       " 'uveitis',\n",
       " 'panuveitis',\n",
       " 'chronic',\n",
       " 'noninfectious',\n",
       " 'anterior',\n",
       " 'uveitis',\n",
       " 'orphan']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "tokens = preprocess_text(raw_text)\n",
    "tokens[:50]  # Show first 50 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Final Structured Output\n",
    "We combine metadata and processed body into a **DataFrame** and save as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>journal_title</th>\n",
       "      <th>article_title</th>\n",
       "      <th>author</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>keywords</th>\n",
       "      <th>cleaned_body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0901c79180555528</td>\n",
       "      <td>Orphan Drug Approvals</td>\n",
       "      <td>FDA Grants Orphan Drug Status to Gevokizumab</td>\n",
       "      <td>Troy Brown</td>\n",
       "      <td>29-08-2012</td>\n",
       "      <td>choroiditis,cyclitis,intermediate uveitis,orph...</td>\n",
       "      <td>webmd llc index troy brown freelance writer me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         article_id          journal_title  \\\n",
       "0  0901c79180555528  Orphan Drug Approvals   \n",
       "\n",
       "                                  article_title      author publication_date  \\\n",
       "0  FDA Grants Orphan Drug Status to Gevokizumab  Troy Brown       29-08-2012   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  choroiditis,cyclitis,intermediate uveitis,orph...   \n",
       "\n",
       "                                   cleaned_body_text  \n",
       "0  webmd llc index troy brown freelance writer me...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([{**metadata, 'cleaned_body_text': ' '.join(tokens)}])\n",
    "df.to_csv('../results/article_data.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Conclusion\n",
    "We successfully parsed an XML medical article, extracted metadata (title, author, keywords, etc.), cleaned and preprocessed the body text for NLP tasks, and stored the results in **CSV and TXT formats**.\n",
    "\n",
    "This workflow can be extended to parse **multiple XML articles** and perform advanced NLP tasks such as **sentiment analysis, keyword extraction, or topic modeling**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
